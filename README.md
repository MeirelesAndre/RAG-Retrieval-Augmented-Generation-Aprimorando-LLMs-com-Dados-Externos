# RAG - Retrieval Augmented Generation

Projeto de demonstraÃ§Ã£o de um sistema RAG (Retrieval-Augmented Generation) com LangChain, utilizando documentos locais (.pdf, .txt, .csv, .docx, .html) como fonte de conhecimento para uma LLM.

> RepositÃ³rio: [github.com/MeirelesAndre/RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos](https://github.com/MeirelesAndre/RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos)

---

## Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#instalaÃ§Ã£o-e-execuÃ§Ã£o)
3. [Blocos do cÃ³digo explicados](#blocos-do-cÃ³digo-explicados)
4. [GlossÃ¡rio](#glossÃ¡rio)
5. [Exemplo de uso](#exemplo-de-uso)

---

## VisÃ£o Geral

Esse projeto implementa um sistema RAG que:

- Permite ao usuÃ¡rio selecionar arquivos locais como fonte de conhecimento
- Utiliza LangChain + Groq + Cohere + Pinecone para processar e responder perguntas
- Suporta arquivos: `.txt`, `.pdf`, `.csv`, `.docx`, `.html`, `.md`

---

## InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone o repositÃ³rio:

```bash
git clone https://github.com/MeirelesAndre/RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos
cd RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos
```

### 2. Crie o ambiente virtual e instale as dependÃªncias:

```bash
python -m venv .venv
source .venv/bin/activate  # ou .venv\Scripts\activate no Windows
pip install -r requirements.txt
```

### 3. Configure suas chaves no arquivo `.env`:

```ini
COHERE_API_KEY=xxxxxx
GROQ_API_KEY=xxxxxx
PINECONE_API_KEY=xxxxxx
```

### 4. Execute o sistema:

```bash
python main.py
```

---

## Blocos do cÃ³digo explicados

### 1. Carregamento de variÃ¡veis de ambiente
Utiliza `dotenv` para carregar as chaves da API do arquivo `.env`.

### 2. SeleÃ§Ã£o de arquivo
Mostra ao usuÃ¡rio os arquivos suportados na pasta `data/` e permite a escolha.

### 3. Carregamento do documento
Detecta a extensÃ£o e aplica o loader correspondente (TextLoader, PyPDFLoader, etc).

### 4. FragmentaÃ§Ã£o de texto
Divide o conteÃºdo em partes menores para facilitar a indexaÃ§Ã£o.

### 5. Gera embeddings
Usa `CohereEmbeddings` para transformar texto em vetores semÃ¢nticos.

### 6. Cria vectorstore (Pinecone)
Indexa os documentos usando Pinecone para buscas vetoriais.

### 7. LLM (ChatGroq)
Define o modelo LLM que gerarÃ¡ respostas a partir dos documentos relevantes.

### 8. MemÃ³ria de conversa (opcional)
MantÃ©m contexto da conversa (pode ser expandido depois).

### 9. Cria a RAG chain
Combina busca com geraÃ§Ã£o usando `create_retrieval_chain`.

### 10. FunÃ§Ã£o interativa
UsuÃ¡rio digita perguntas e recebe respostas com base no documento selecionado.

---

## GlossÃ¡rio

| Termo           | DefiniÃ§Ã£o |
|----------------|------------|
| **RAG**        | Retrieval-Augmented Generation: geraÃ§Ã£o de texto com apoio de busca externa. |
| **LLM**        | Large Language Model. Ex: ChatGPT, Gemma, LLaMA. |
| **Embedding**  | Vetor que representa o significado de um texto. |
| **Pinecone**   | Banco vetorial para busca por similaridade. |
| **LangChain**  | Framework para conectar LLMs com outras fontes e fluxos. |
| **Groq**       | Plataforma para executar LLMs com alta performance. |

---

## Exemplo de uso

```bash
python main.py

# SaÃ­da:
ğŸ“‚ Selecione o arquivo desejado:
1. exemplo.pdf
2. texto.txt
...

â“ No que posso ajudar â“
> Qual Ã© o assunto do documento?

ğŸ§  Resposta:
O documento aborda...
```

---


Feito com ğŸ’¡ por [@MeirelesAndre](https://github.com/MeirelesAndre)

