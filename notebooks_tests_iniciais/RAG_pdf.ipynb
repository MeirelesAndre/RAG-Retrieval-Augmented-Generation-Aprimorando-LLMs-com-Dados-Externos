{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3007a323",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0855337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain langchain-cohere langchain-groq langchain-community langchain-pinecone python-dotenv  pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00b355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\RAG Retrieval-Augmented Generation\\RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importação de bibliotecas para lidar com variáveis de ambiente\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Loaders para carregar arquivos de texto e PDF\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Ferramentas para dividir documentos em partes menores\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Geração de embeddings com Cohere\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "# Integração com o vetorstore Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Memória de conversa (não utilizada no trecho atual, mas importada)\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# LLM da Groq (ChatGPT acelerado por hardware especializado)\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Acesso ao hub de chains pré-construídas do LangChain\n",
    "from langchain import hub\n",
    "\n",
    "# Chains para combinar documentos e fazer busca com recuperação\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Vectorstore local alternativo (FAISS), não utilizado nesse código\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3445c3",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac6b35",
   "metadata": {},
   "source": [
    "Chaves API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37cd9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Obtém as chaves de API das variáveis de ambiente\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d76a8b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHERE_API_KEY: TOEQPo2gzPWKLP7SUpwAW3svbK3Vwm7tZOkU6FX5\n",
      "PINECONE_API_KEY: pcsk_65d8mR_TRTfYVcecxyGRyRQPFNARgkRmit2WWY75Q4KVx3YFmmXHA3tiUKWZbsSzYsQSY5\n",
      "GROQ_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "# Conferindo e pegou as Chaves corretamente\n",
    "print(f\"COHERE_API_KEY: {COHERE_API_KEY}\")  # Debug temporário\n",
    "print(f\"PINECONE_API_KEY: {PINECONE_API_KEY}\")  # Debug temporário\n",
    "print(f\"GROQ_API_KEY: {GROQ_API_KEY}\")  # Debug temporário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d49813",
   "metadata": {},
   "source": [
    "Carregando e cortando arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9e685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o conteúdo do arquivo PDF\n",
    "loader = PyPDFLoader('../data/2210.03629v3.pdf')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4936b8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de partes criadas: 129\n"
     ]
    }
   ],
   "source": [
    "# Divide o texto em partes menores para facilitar a vetorização\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000,chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Mostra quantas partes foram geradas\n",
    "print(f\"Total de partes criadas: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc2ce2",
   "metadata": {},
   "source": [
    "Incorporando agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia os embeddings usando o modelo da Cohere\n",
    "embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\",\n",
    "    cohere_api_key=COHERE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991034f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do índice no Pinecone (deve já existir no console do Pinecone)\n",
    "index_name = \"pdf-demo\"\n",
    "\n",
    "# Cria o vetorstore a partir dos documentos, com os embeddings e configurações do Pinecone\n",
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "    docs,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "651aa0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='69385612-be28-4b2f-b6e9-6053f3bc33bc', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 30.0, 'page_label': '31', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\nD.3 W EBSHOP TRAJECTORIES\\nTable 10: Example trajectories for Webshop predicted by Act and ReAct. Compared to Act,\\nReAct uses reasoning to ﬁnd products that satisfy all target attributes.\\nInstruction: get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars\\nAct ReAct\\nAction: search\\n[\\nsixteen pack apple cinnamon freeze dried banana\\nchips\\n]\\nObservation:[\\nBack to Search\\n]\\nPage 1 (Total results: 50)[\\nNext\\n]\\n[\\nB0061IVFZE\\n]\\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\\nOunce (Pack of 100)\\n$85.0[\\nB096H2P6G2\\n]\\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\\n(Variety Pack)\\n$18.99[\\nB092JLLYK6\\n]\\nNature’s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\\nNon GMO, Gluten Free, Nothing Artiﬁcial (0.53oz) 6-Pack\\n$12.99\\nAction: click\\n[\\nB0061IVFZE\\n]\\nObservation:[\\nBack to Search\\n]\\n[\\nPrev\\n]'), Document(id='9cbfe3a9-356f-432e-b370-be10043d5db4', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 30.0, 'page_label': '31', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\nD.3 W EBSHOP TRAJECTORIES\\nTable 10: Example trajectories for Webshop predicted by Act and ReAct. Compared to Act,\\nReAct uses reasoning to ﬁnd products that satisfy all target attributes.\\nInstruction: get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars\\nAct ReAct\\nAction: search\\n[\\nsixteen pack apple cinnamon freeze dried banana\\nchips\\n]\\nObservation:[\\nBack to Search\\n]\\nPage 1 (Total results: 50)[\\nNext\\n]\\n[\\nB0061IVFZE\\n]\\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\\nOunce (Pack of 100)\\n$85.0[\\nB096H2P6G2\\n]\\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\\n(Variety Pack)\\n$18.99[\\nB092JLLYK6\\n]\\nNature’s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\\nNon GMO, Gluten Free, Nothing Artiﬁcial (0.53oz) 6-Pack\\n$12.99\\nAction: click\\n[\\nB0061IVFZE\\n]\\nObservation:[\\nBack to Search\\n]\\n[\\nPrev\\n]'), Document(id='eeb8f9ab-0bad-4e40-87b2-1d5dafdc6b45', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 9.0, 'page_label': '10', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\nwith initial promising results, but learning from more high-quality human annotations will be the\\ndesiderata to further improve the performance. Scaling up ReAct with multi-task training and\\ncombining it with complementary paradigms like reinforcement learning could result in stronger\\nagents that further unlock the potential of LLMs for more applications.\\nACKNOWLEDGMENTS\\nWe thank the support and feedback of many people from Google Brain team and Princeton NLP\\nGroup. This work was supported in part by the National Science Foundation under Grant No.\\n2107048. Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are\\nthose of the author(s) and do not necessarily reﬂect the views of the National Science Foundation.\\nREPRODUCIBILITY STATEMENT\\nOur main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible'), Document(id='4f0fc7e8-7e06-42ef-aefa-97737b67d395', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 9.0, 'page_label': '10', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\nwith initial promising results, but learning from more high-quality human annotations will be the\\ndesiderata to further improve the performance. Scaling up ReAct with multi-task training and\\ncombining it with complementary paradigms like reinforcement learning could result in stronger\\nagents that further unlock the potential of LLMs for more applications.\\nACKNOWLEDGMENTS\\nWe thank the support and feedback of many people from Google Brain team and Princeton NLP\\nGroup. This work was supported in part by the National Science Foundation under Grant No.\\n2107048. Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are\\nthose of the author(s) and do not necessarily reﬂect the views of the National Science Foundation.\\nREPRODUCIBILITY STATEMENT\\nOur main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible')]\n"
     ]
    }
   ],
   "source": [
    "# Teste uma busca semântica:\n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "print(vectorstore.similarity_search(\"What is a vector store?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62a5ea",
   "metadata": {},
   "source": [
    "Criando LLM e Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0eaaf050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o LLM da Groq com Gemma2\n",
    "llm = ChatGroq(\n",
    "    model=\"Gemma2-9b-It\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    temperature=0.1\n",
    ")                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6193876d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\RAG Retrieval-Augmented Generation\\RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos\\.venv\\Lib\\site-packages\\langsmith\\client.py:278: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cria a chain de resposta com base nos documentos\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, retrieval_qa_chat_prompt)\n",
    "\n",
    "# Cria o retriever para buscar documentos relevantes\n",
    "retriever = vectorstore_from_docs.as_retriever()\n",
    "\n",
    "# Cria a chain de RAG combinando busca + geração\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d69357c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Pergunta: O que é React? Responda em português.\n",
      "💬 Resposta: \n",
      "\n",
      "ReAct é um paradigma geral que combina raciocínio e ação com modelos de linguagem para resolver diversas tarefas de raciocínio e tomada de decisão em linguagem. \n",
      "\n",
      "Ele funciona promptando os modelos de linguagem a gerar tanto raciocínios verbais quanto ações relacionadas a uma tarefa de forma intercalada. Isso permite que o modelo realize raciocínio dinâmico para criar, manter e ajustar planos de alto nível para agir (\"raciocinar para agir\"), além de interagir com ambientes externos (como a Wikipedia) para incorporar informações adicionais ao raciocínio (\"agir para raciocinar\"). \n",
      "\n",
      "\n",
      "Em resumo, ReAct visa integrar a capacidade de pensar e agir em modelos de linguagem para solucionar problemas de forma mais completa e eficiente. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testanto LLM \n",
    "res = rag_chain.invoke({\"input\":\"O que é React? Responda em português.\"})\n",
    "print(\"🔍 Pergunta: O que é React? Responda em português.\")\n",
    "print(\"💬 Resposta: \\n\")\n",
    "print(res['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed0109",
   "metadata": {},
   "source": [
    "## Finalização com interação com o usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c977436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função interativa\n",
    "def fazer_pergunta_rag():\n",
    "    while True:\n",
    "        pergunta = input(\"\\n ❓ No que posso ajudar ❓ (ou digite 'sair' para encerrar):\\n> \")\n",
    "        \n",
    "        if pergunta.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "            print(\"Encerrando. Até logo!\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            resposta = rag_chain.invoke({\"input\":f\"{pergunta} Responda em português\"})\n",
    "            print(f'🔍 Pergunta: {pergunta}')\n",
    "            print(\"\\n🧠 Resposta:\\n\")\n",
    "            print(resposta[\"answer\"])\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Erro ao gerar resposta: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bde85e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Pergunta: O que é react\n",
      "\n",
      "🧠 Resposta:\n",
      "\n",
      "O texto descreve um modelo chamado ReAct, que visa tornar as tarefas de resolução de problemas de grandes modelos de linguagem (LLMs) mais interpretáveis, diagnosticáveis e controlados por humanos. \n",
      "\n",
      "O ReAct conecta LLMs com um espaço de ações para interagir com ambientes externos, como a web ou ambientes físicos. No entanto, os autores reconhecem os potenciais perigos dessa conexão, como o acesso a informações privadas ou a execução de ações prejudiciais. \n",
      "\n",
      "Para minimizar esses riscos, os experimentos do ReAct se limitam a interações com sites específicos (Wikipedia ou WebShop) que não contêm informações privadas e sem ações perigosas no espaço de ações (os modelos não podem realmente comprar produtos no WebShop).\n",
      "\n",
      "O texto também menciona que os autores fornecem todos os prompts usados, experimentos adicionais com GPT-3 e o código de prompting GPT-3 ReAct para aumentar a reprodutibilidade do estudo.\n",
      "\n",
      "\n",
      "Em resumo, o ReAct é um modelo que tenta tornar os LLMs mais úteis e seguros ao permitir que eles interajam com o mundo real de forma controlada. \n",
      "\n",
      "Encerrando. Até logo!\n"
     ]
    }
   ],
   "source": [
    "# Execução\n",
    "if __name__ == \"__main__\":\n",
    "    fazer_pergunta_rag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
