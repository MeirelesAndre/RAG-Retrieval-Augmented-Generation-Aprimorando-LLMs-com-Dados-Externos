{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3007a323",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0855337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain langchain-cohere langchain-groq langchain-community langchain-pinecone python-dotenv  pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00b355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\RAG Retrieval-Augmented Generation\\RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importa√ß√£o de bibliotecas para lidar com vari√°veis de ambiente\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Loaders para carregar arquivos de texto e PDF\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Ferramentas para dividir documentos em partes menores\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Gera√ß√£o de embeddings com Cohere\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "# Integra√ß√£o com o vetorstore Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Mem√≥ria de conversa (n√£o utilizada no trecho atual, mas importada)\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# LLM da Groq (ChatGPT acelerado por hardware especializado)\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Acesso ao hub de chains pr√©-constru√≠das do LangChain\n",
    "from langchain import hub\n",
    "\n",
    "# Chains para combinar documentos e fazer busca com recupera√ß√£o\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Vectorstore local alternativo (FAISS), n√£o utilizado nesse c√≥digo\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3445c3",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac6b35",
   "metadata": {},
   "source": [
    "Chaves API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37cd9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega as vari√°veis de ambiente do arquivo .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Obt√©m as chaves de API das vari√°veis de ambiente\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d76a8b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHERE_API_KEY: TOEQPo2gzPWKLP7SUpwAW3svbK3Vwm7tZOkU6FX5\n",
      "PINECONE_API_KEY: pcsk_65d8mR_TRTfYVcecxyGRyRQPFNARgkRmit2WWY75Q4KVx3YFmmXHA3tiUKWZbsSzYsQSY5\n",
      "GROQ_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "# Conferindo e pegou as Chaves corretamente\n",
    "print(f\"COHERE_API_KEY: {COHERE_API_KEY}\")  # Debug tempor√°rio\n",
    "print(f\"PINECONE_API_KEY: {PINECONE_API_KEY}\")  # Debug tempor√°rio\n",
    "print(f\"GROQ_API_KEY: {GROQ_API_KEY}\")  # Debug tempor√°rio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d49813",
   "metadata": {},
   "source": [
    "Carregando e cortando arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9e685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o conte√∫do do arquivo PDF\n",
    "loader = PyPDFLoader('../data/2210.03629v3.pdf')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4936b8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de partes criadas: 129\n"
     ]
    }
   ],
   "source": [
    "# Divide o texto em partes menores para facilitar a vetoriza√ß√£o\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000,chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Mostra quantas partes foram geradas\n",
    "print(f\"Total de partes criadas: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc2ce2",
   "metadata": {},
   "source": [
    "Incorporando agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia os embeddings usando o modelo da Cohere\n",
    "embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\",\n",
    "    cohere_api_key=COHERE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991034f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do √≠ndice no Pinecone (deve j√° existir no console do Pinecone)\n",
    "index_name = \"pdf-demo\"\n",
    "\n",
    "# Cria o vetorstore a partir dos documentos, com os embeddings e configura√ß√µes do Pinecone\n",
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "    docs,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "651aa0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='69385612-be28-4b2f-b6e9-6053f3bc33bc', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 30.0, 'page_label': '31', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\nD.3 W EBSHOP TRAJECTORIES\\nTable 10: Example trajectories for Webshop predicted by Act and ReAct. Compared to Act,\\nReAct uses reasoning to Ô¨Ånd products that satisfy all target attributes.\\nInstruction: get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars\\nAct ReAct\\nAction: search\\n[\\nsixteen pack apple cinnamon freeze dried banana\\nchips\\n]\\nObservation:[\\nBack to Search\\n]\\nPage 1 (Total results: 50)[\\nNext\\n]\\n[\\nB0061IVFZE\\n]\\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\\nOunce (Pack of 100)\\n$85.0[\\nB096H2P6G2\\n]\\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\\n(Variety Pack)\\n$18.99[\\nB092JLLYK6\\n]\\nNature‚Äôs Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\\nNon GMO, Gluten Free, Nothing ArtiÔ¨Åcial (0.53oz) 6-Pack\\n$12.99\\nAction: click\\n[\\nB0061IVFZE\\n]\\nObservation:[\\nBack to Search\\n]\\n[\\nPrev\\n]'), Document(id='9cbfe3a9-356f-432e-b370-be10043d5db4', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 30.0, 'page_label': '31', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\nD.3 W EBSHOP TRAJECTORIES\\nTable 10: Example trajectories for Webshop predicted by Act and ReAct. Compared to Act,\\nReAct uses reasoning to Ô¨Ånd products that satisfy all target attributes.\\nInstruction: get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars\\nAct ReAct\\nAction: search\\n[\\nsixteen pack apple cinnamon freeze dried banana\\nchips\\n]\\nObservation:[\\nBack to Search\\n]\\nPage 1 (Total results: 50)[\\nNext\\n]\\n[\\nB0061IVFZE\\n]\\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\\nOunce (Pack of 100)\\n$85.0[\\nB096H2P6G2\\n]\\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\\n(Variety Pack)\\n$18.99[\\nB092JLLYK6\\n]\\nNature‚Äôs Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\\nNon GMO, Gluten Free, Nothing ArtiÔ¨Åcial (0.53oz) 6-Pack\\n$12.99\\nAction: click\\n[\\nB0061IVFZE\\n]\\nObservation:[\\nBack to Search\\n]\\n[\\nPrev\\n]'), Document(id='eeb8f9ab-0bad-4e40-87b2-1d5dafdc6b45', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 9.0, 'page_label': '10', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\nwith initial promising results, but learning from more high-quality human annotations will be the\\ndesiderata to further improve the performance. Scaling up ReAct with multi-task training and\\ncombining it with complementary paradigms like reinforcement learning could result in stronger\\nagents that further unlock the potential of LLMs for more applications.\\nACKNOWLEDGMENTS\\nWe thank the support and feedback of many people from Google Brain team and Princeton NLP\\nGroup. This work was supported in part by the National Science Foundation under Grant No.\\n2107048. Any opinions, Ô¨Åndings, and conclusions or recommendations expressed in this material are\\nthose of the author(s) and do not necessarily reÔ¨Çect the views of the National Science Foundation.\\nREPRODUCIBILITY STATEMENT\\nOur main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible'), Document(id='4f0fc7e8-7e06-42ef-aefa-97737b67d395', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 9.0, 'page_label': '10', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'data/2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\nwith initial promising results, but learning from more high-quality human annotations will be the\\ndesiderata to further improve the performance. Scaling up ReAct with multi-task training and\\ncombining it with complementary paradigms like reinforcement learning could result in stronger\\nagents that further unlock the potential of LLMs for more applications.\\nACKNOWLEDGMENTS\\nWe thank the support and feedback of many people from Google Brain team and Princeton NLP\\nGroup. This work was supported in part by the National Science Foundation under Grant No.\\n2107048. Any opinions, Ô¨Åndings, and conclusions or recommendations expressed in this material are\\nthose of the author(s) and do not necessarily reÔ¨Çect the views of the National Science Foundation.\\nREPRODUCIBILITY STATEMENT\\nOur main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible')]\n"
     ]
    }
   ],
   "source": [
    "# Teste uma busca sem√¢ntica:\n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "print(vectorstore.similarity_search(\"What is a vector store?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62a5ea",
   "metadata": {},
   "source": [
    "Criando LLM e Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0eaaf050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o LLM da Groq com Gemma2\n",
    "llm = ChatGroq(\n",
    "    model=\"Gemma2-9b-It\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    temperature=0.1\n",
    ")                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6193876d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\RAG Retrieval-Augmented Generation\\RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos\\.venv\\Lib\\site-packages\\langsmith\\client.py:278: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cria a chain de resposta com base nos documentos\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, retrieval_qa_chat_prompt)\n",
    "\n",
    "# Cria o retriever para buscar documentos relevantes\n",
    "retriever = vectorstore_from_docs.as_retriever()\n",
    "\n",
    "# Cria a chain de RAG combinando busca + gera√ß√£o\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d69357c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Pergunta: O que √© React? Responda em portugu√™s.\n",
      "üí¨ Resposta: \n",
      "\n",
      "ReAct √© um paradigma geral que combina racioc√≠nio e a√ß√£o com modelos de linguagem para resolver diversas tarefas de racioc√≠nio e tomada de decis√£o em linguagem. \n",
      "\n",
      "Ele funciona promptando os modelos de linguagem a gerar tanto racioc√≠nios verbais quanto a√ß√µes relacionadas a uma tarefa de forma intercalada. Isso permite que o modelo realize racioc√≠nio din√¢mico para criar, manter e ajustar planos de alto n√≠vel para agir (\"raciocinar para agir\"), al√©m de interagir com ambientes externos (como a Wikipedia) para incorporar informa√ß√µes adicionais ao racioc√≠nio (\"agir para raciocinar\"). \n",
      "\n",
      "\n",
      "Em resumo, ReAct visa integrar a capacidade de pensar e agir em modelos de linguagem para solucionar problemas de forma mais completa e eficiente. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testanto LLM \n",
    "res = rag_chain.invoke({\"input\":\"O que √© React? Responda em portugu√™s.\"})\n",
    "print(\"üîç Pergunta: O que √© React? Responda em portugu√™s.\")\n",
    "print(\"üí¨ Resposta: \\n\")\n",
    "print(res['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed0109",
   "metadata": {},
   "source": [
    "## Finaliza√ß√£o com intera√ß√£o com o usu√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c977436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o interativa\n",
    "def fazer_pergunta_rag():\n",
    "    while True:\n",
    "        pergunta = input(\"\\n ‚ùì No que posso ajudar ‚ùì (ou digite 'sair' para encerrar):\\n> \")\n",
    "        \n",
    "        if pergunta.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "            print(\"Encerrando. At√© logo!\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            resposta = rag_chain.invoke({\"input\":f\"{pergunta} Responda em portugu√™s\"})\n",
    "            print(f'üîç Pergunta: {pergunta}')\n",
    "            print(\"\\nüß† Resposta:\\n\")\n",
    "            print(resposta[\"answer\"])\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Erro ao gerar resposta: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bde85e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Pergunta: O que √© react\n",
      "\n",
      "üß† Resposta:\n",
      "\n",
      "O texto descreve um modelo chamado ReAct, que visa tornar as tarefas de resolu√ß√£o de problemas de grandes modelos de linguagem (LLMs) mais interpret√°veis, diagnostic√°veis e controlados por humanos. \n",
      "\n",
      "O ReAct conecta LLMs com um espa√ßo de a√ß√µes para interagir com ambientes externos, como a web ou ambientes f√≠sicos. No entanto, os autores reconhecem os potenciais perigos dessa conex√£o, como o acesso a informa√ß√µes privadas ou a execu√ß√£o de a√ß√µes prejudiciais. \n",
      "\n",
      "Para minimizar esses riscos, os experimentos do ReAct se limitam a intera√ß√µes com sites espec√≠ficos (Wikipedia ou WebShop) que n√£o cont√™m informa√ß√µes privadas e sem a√ß√µes perigosas no espa√ßo de a√ß√µes (os modelos n√£o podem realmente comprar produtos no WebShop).\n",
      "\n",
      "O texto tamb√©m menciona que os autores fornecem todos os prompts usados, experimentos adicionais com GPT-3 e o c√≥digo de prompting GPT-3 ReAct para aumentar a reprodutibilidade do estudo.\n",
      "\n",
      "\n",
      "Em resumo, o ReAct √© um modelo que tenta tornar os LLMs mais √∫teis e seguros ao permitir que eles interajam com o mundo real de forma controlada. \n",
      "\n",
      "Encerrando. At√© logo!\n"
     ]
    }
   ],
   "source": [
    "# Execu√ß√£o\n",
    "if __name__ == \"__main__\":\n",
    "    fazer_pergunta_rag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
