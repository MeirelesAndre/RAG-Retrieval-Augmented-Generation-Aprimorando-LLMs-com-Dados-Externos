{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain langchain-cohere langchain-groq langchain-community langchain-pinecone python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\RAG Retrieval-Augmented Generation\\RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importação de bibliotecas para lidar com variáveis de ambiente\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Loaders para carregar arquivos de texto e PDF\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Ferramentas para dividir documentos em partes menores\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Geração de embeddings com Cohere\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "# Integração com o vetorstore Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Memória de conversa (não utilizada no trecho atual, mas importada)\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# LLM da Groq (ChatGPT acelerado por hardware especializado)\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Acesso ao hub de chains pré-construídas do LangChain\n",
    "from langchain import hub\n",
    "\n",
    "# Chains para combinar documentos e fazer busca com recuperação\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Vectorstore local alternativo (FAISS), não utilizado nesse código\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaves das APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Obtém as chaves de API das variáveis de ambiente\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHERE_API_KEY: TOEQPo2gzPWKLP7SUpwAW3svbK3Vwm7tZOkU6FX5\n",
      "PINECONE_API_KEY: pcsk_65d8mR_TRTfYVcecxyGRyRQPFNARgkRmit2WWY75Q4KVx3YFmmXHA3tiUKWZbsSzYsQSY5\n",
      "GROQ_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "# Conferindo e pegou as Chaves corretamente\n",
    "print(f\"COHERE_API_KEY: {COHERE_API_KEY}\")  # Debug temporário\n",
    "print(f\"PINECONE_API_KEY: {PINECONE_API_KEY}\")  # Debug temporário\n",
    "print(f\"GROQ_API_KEY: {GROQ_API_KEY}\")  # Debug temporário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o conteúdo do arquivo de texto\n",
    "loader = TextLoader(\"../data/mediumblog1.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de partes criadas: 4\n"
     ]
    }
   ],
   "source": [
    "# Divide o texto em partes menores para facilitar a vetorização\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000,chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Mostra quantas partes foram geradas\n",
    "print(f\"Total de partes criadas: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporando agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia os embeddings usando o modelo da Cohere\n",
    "embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\",\n",
    "    cohere_api_key=COHERE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do índice no Pinecone (deve já existir no console do Pinecone)\n",
    "index_name = \"rag-demo\"\n",
    "\n",
    "# Cria o vetorstore a partir dos documentos, com os embeddings e configurações do Pinecone\n",
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "    docs,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='05cd1c2a-2322-437e-b72b-1b35a5e74f2f', metadata={'source': 'data/mediumblog1.txt'}, page_content='Title: Vector Database: What is it and Why You Should Know It?\\n\\nAuthor: Ejiro Onose\\nDate: December 22, 2023\\n\\nIf 2021 was the year of graph databases, 2023 is the year of vector databases â€” Chip Huen.\\n\\nGenerative AI and Large Language Models (LLMs) have become popular, and a vector database is one of the best tools to handle LLM data. Vector databases provide the ideal infrastructure for managing the complex, high-dimensional data that LLMs produce and rely upon.\\n\\nIn this article, Iâ€™ll explain what vector databases are, how they work, and introduce some top vector database tools.\\n\\n What is a Vector?\\nIn machine learning (ML), a vector is a collection of numerical values that represents the features of multi-dimensional objects, such as words or images. For example, a vector representing an image might contain values related to pixel intensities and color channels.'), Document(id='6bf282e2-4c2f-4696-b7f6-cf553c0adb40', metadata={'source': 'data/mediumblog1.txt'}, page_content='Title: Vector Database: What is it and Why You Should Know It?\\n\\nAuthor: Ejiro Onose\\nDate: December 22, 2023\\n\\nIf 2021 was the year of graph databases, 2023 is the year of vector databases â€” Chip Huen.\\n\\nGenerative AI and Large Language Models (LLMs) have become popular, and a vector database is one of the best tools to handle LLM data. Vector databases provide the ideal infrastructure for managing the complex, high-dimensional data that LLMs produce and rely upon.\\n\\nIn this article, Iâ€™ll explain what vector databases are, how they work, and introduce some top vector database tools.\\n\\n What is a Vector?\\nIn machine learning (ML), a vector is a collection of numerical values that represents the features of multi-dimensional objects, such as words or images. For example, a vector representing an image might contain values related to pixel intensities and color channels.'), Document(id='56cced7c-24a0-4efe-a500-58a098df19b2', metadata={'source': 'data/mediumblog1.txt'}, page_content='Title: Vector Database: What is it and Why You Should Know It?\\n\\nAuthor: Ejiro Onose\\nDate: December 22, 2023\\n\\nIf 2021 was the year of graph databases, 2023 is the year of vector databases â€” Chip Huen.\\n\\nGenerative AI and Large Language Models (LLMs) have become popular, and a vector database is one of the best tools to handle LLM data. Vector databases provide the ideal infrastructure for managing the complex, high-dimensional data that LLMs produce and rely upon.\\n\\nIn this article, Iâ€™ll explain what vector databases are, how they work, and introduce some top vector database tools.\\n\\n What is a Vector?\\nIn machine learning (ML), a vector is a collection of numerical values that represents the features of multi-dimensional objects, such as words or images. For example, a vector representing an image might contain values related to pixel intensities and color channels.'), Document(id='042f501e-f059-45dd-9361-bd8ff64e153f', metadata={'source': 'data/mediumblog1.txt'}, page_content='Title: Vector Database: What is it and Why You Should Know It?\\n\\nAuthor: Ejiro Onose\\nDate: December 22, 2023\\n\\nIf 2021 was the year of graph databases, 2023 is the year of vector databases â€” Chip Huen.\\n\\nGenerative AI and Large Language Models (LLMs) have become popular, and a vector database is one of the best tools to handle LLM data. Vector databases provide the ideal infrastructure for managing the complex, high-dimensional data that LLMs produce and rely upon.\\n\\nIn this article, Iâ€™ll explain what vector databases are, how they work, and introduce some top vector database tools.\\n\\n What is a Vector?\\nIn machine learning (ML), a vector is a collection of numerical values that represents the features of multi-dimensional objects, such as words or images. For example, a vector representing an image might contain values related to pixel intensities and color channels.')]\n"
     ]
    }
   ],
   "source": [
    "# Teste uma busca semântica:\n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "print(vectorstore.similarity_search(\"What is a vector store?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando LLM e Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o LLM da Groq com Gemma2\n",
    "llm = ChatGroq(\n",
    "    model=\"Gemma2-9b-It\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    temperature=0.1\n",
    ")                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINDOWS 10\\AppData\\Local\\Temp\\ipykernel_4796\\2577572416.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "c:\\Users\\WINDOWS 10\\RAG Retrieval-Augmented Generation\\RAG-Retrieval-Augmented-Generation-Aprimorando-LLMs-com-Dados-Externos\\.venv\\Lib\\site-packages\\langsmith\\client.py:278: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cria a chain de resposta com base nos documentos\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, retrieval_qa_chat_prompt)\n",
    "\n",
    "# Cria o retriever para buscar documentos relevantes\n",
    "retriever = vectorstore_from_docs.as_retriever()\n",
    "\n",
    "# Cria a chain de RAG combinando busca + geração\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Pergunta: O que é React? Responda em português.\n",
      "💬 Resposta: \n",
      "\n",
      "ReAct é um novo paradigma para combinar raciocínio e ação com modelos de linguagem grandes (LLMs) para resolver tarefas de raciocínio e tomada de decisão em linguagem. \n",
      "\n",
      "Em essência, o ReAct incentiva o LLM a gerar tanto traços de raciocínio verbal quanto ações relacionadas a uma tarefa de forma interligada. Isso permite que o modelo realize raciocínio dinâmico para criar, manter e ajustar planos de alto nível para agir (\"raciocinar para agir\"), ao mesmo tempo em que interage com ambientes externos (como a Wikipedia) para incorporar informações adicionais no raciocínio (\"agir para raciocinar\").\n",
      "\n",
      "\n",
      "O texto destaca algumas características importantes do ReAct:\n",
      "\n",
      "* **Intuitivo e fácil de projetar:** A criação de prompts para o ReAct é simples, pois os anotadores humanos apenas digitam seus pensamentos em linguagem sobre as ações que tomam.\n",
      "* **Geral e flexível:** Devido ao espaço de pensamento flexível e ao formato de ocorrência de pensamento-ação, o ReAct funciona para tarefas diversas com espaços de ação e necessidades de raciocínio distintos.\n",
      "* **Eficaz e robusto:** O ReAct demonstra forte generalização para novas instâncias de tarefas, superando consistentemente modelos base que utilizam apenas raciocínio ou ação.\n",
      "* **Alinhado com humanos e controlável:** O ReAct promete um processo de tomada de decisão e raciocínio sequencial interpretável, onde os humanos podem facilmente inspecionar o raciocínio e a correção factual. Além disso, os humanos também podem controlar ou corrigir o comportamento do agente em tempo real por meio da edição de pensamentos.\n",
      "\n",
      "\n",
      "Em resumo, o ReAct é uma abordagem promissora para integrar raciocínio e ação em LLMs, abrindo caminho para novas aplicações em tarefas complexas que exigem compreensão e interação com o mundo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testanto LLM \n",
    "res = rag_chain.invoke({\"input\":\"O que é React? Responda em português.\"})\n",
    "print(\"🔍 Pergunta: O que é React? Responda em português.\")\n",
    "print(\"💬 Resposta: \\n\")\n",
    "print(res['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalização com interação com o usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função interativa\n",
    "def fazer_pergunta_rag():\n",
    "    while True:\n",
    "        pergunta = input(\"\\n ❓ No que posso ajudar ❓ (ou digite 'sair' para encerrar):\\n> \")\n",
    "        \n",
    "        if pergunta.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "            print(\"Encerrando. Até logo!\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            resposta = rag_chain.invoke({\"input\":f\"{pergunta} Responda em português\"})\n",
    "            print(\"\\n🧠 Resposta:\\n\")\n",
    "            print(resposta[\"answer\"])\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Erro ao gerar resposta: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Resposta:\n",
      "\n",
      "ReAct é um framework para tarefas de tomada de decisão e raciocínio sequenciais, baseado em modelos de linguagem grandes. \n",
      "\n",
      "Ele funciona assim:\n",
      "\n",
      "* **Pensamento e Ação:** ReAct permite que um modelo de linguagem \"pense\" (formulando pensamentos em linguagem natural) e \"aja\" (executando ações em um ambiente).\n",
      "* **Trajetórias:** As interações do modelo são representadas como trajetórias, onde cada etapa consiste em um pensamento, uma ação e uma observação resultante.\n",
      "* **Aprendizado por Exemplo:** ReAct aprende com exemplos de trajetórias pré-definidas, chamadas de \"trajetórias densas\", onde os pensamentos são explicitamente fornecidos.\n",
      "* **Flexibilidade:** A estrutura flexível de ReAct permite sua aplicação em diversas tarefas, como perguntas e respostas, verificação de fatos, jogos de texto e navegação na web.\n",
      "\n",
      "**Vantagens do ReAct:**\n",
      "\n",
      "* **Intuitivo e Fácil de Projetar:** A criação de prompts para ReAct é simples, pois os humanos apenas digitam os pensamentos em linguagem natural.\n",
      "* **Geral e Flexível:** ReAct pode ser usado em uma variedade de tarefas com diferentes espaços de ações e necessidades de raciocínio.\n",
      "* **Eficaz e Robusto:** ReAct demonstra desempenho consistente em tarefas de conhecimento intensivo, aprendendo com poucos exemplos e superando modelos base que apenas raciocinam ou agem.\n",
      "* **Alinhado com Humanos e Controlável:** ReAct permite a inspeção do processo de raciocínio e tomada de decisão, além de permitir que os humanos controlem ou corrijam o comportamento do agente em tempo real.\n",
      "\n",
      "\n",
      "Em resumo, ReAct é uma abordagem promissora para o raciocínio e tomada de decisão sequencial em modelos de linguagem, combinando a capacidade de raciocínio de modelos de linguagem com a flexibilidade e controle humano.\n",
      "\n",
      "Encerrando. Até logo!\n"
     ]
    }
   ],
   "source": [
    "# Execução\n",
    "if __name__ == \"__main__\":\n",
    "    fazer_pergunta_rag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
